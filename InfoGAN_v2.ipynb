{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "InfoGAN_v2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Fp8GCSHt0rOb"
      },
      "source": [
        "# InfoGAN\n",
        "<center><img src=\"https://drive.google.com/uc?id=1_eHGgFAACgcf80S1Oi_4Qax2nPxQP6O2\" width=\"700\" height=\"350\"></center>\n",
        "\n",
        "Latent 코드 $c$ 는 생성기(Generator) 입력의 일부분이며 각 분포를 나타내는 변수(continuous, categorial)를 포함하고 있다.\n",
        "\n",
        "제너레이터가 Latent 코드 c를 사용하도록 하기 위해, 상호정보량개념(mutual information)이 GAN의 손실함수에 도입된다. \n",
        "\n",
        "mutual information(I)는 Y가 주어진 X의 양을 측정하거나 그 반대도 측정한다. 이것은 아래와 같이 정의된다.  \n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "$$I(X;Y) = entropy(X) - entropy(X|Y) = entropy(Y) - entropy(Y|X) $$\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "The InfoGAN loss is: \n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "$$\\min_{G} \\max_{D} \\, V(D, G) - \\lambda I(c, G(z, c))$$\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "여기서 $V(D,G)$ 는 GAN의 손실함수이다. $I(c, G(z, c))$는 상호정보량(I)이다(goes in as regularization). 목표는 데이터에 대한 의미있는 코드 c를 배우기 위해 높은 상호정보량에 도달하는 것이다. \n",
        "\n",
        "---\n",
        "\n",
        "Loss functions\n",
        "\n",
        "*   Categorical code c : SoftmaxCrossEntropyLoss\n",
        "*   Continious code c : L2Loss\n",
        "*   Normal GAN loss : SigmoidBinaryCrossEntropyLoss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "q-Ku-tY8qZWB"
      },
      "source": [
        "## TensorFlow 및 기타 라이브러리 가져오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GbPLzJM7n_dS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "outputId": "518facf2-36f4-4889-ebfc-6ebb477b6fef"
      },
      "source": [
        "import tensorflow as tf\n",
        "slim = tf.contrib.slim\n",
        "tfd = tf.distributions\n",
        "\n",
        "from tensorflow.examples.tutorials.mnist import input_data"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0825 16:19:24.515990 140166383638400 lazy_loader.py:50] \n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7LraRe1sqbpV"
      },
      "source": [
        "Load the MNIST dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NEZtygTjqeBj",
        "outputId": "7fcb929d-7cba-425b-b8a9-d06c34c97ec6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "source": [
        "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0825 16:19:24.537600 140166383638400 deprecation.py:323] From <ipython-input-2-a839aeb82f4b>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "W0825 16:19:24.538805 140166383638400 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "W0825 16:19:24.540583 140166383638400 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0825 16:19:24.824619 140166383638400 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "W0825 16:19:24.827623 140166383638400 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "W0825 16:19:24.883741 140166383638400 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EaDUUa3SqhHP"
      },
      "source": [
        "## InfoGAN 네트워크 생성\n",
        "<center><img src=\"https://drive.google.com/uc?id=18msRuNcK_oXw2UReSrya0fcpRT-ZKdzZ\" width=\"600\" height=\"200\"></center>\n",
        "\n",
        "논문에 네트워크 구조가 정의되어 있음"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "swXpGbhUoD2d",
        "colab": {}
      },
      "source": [
        "def generator(z, out_activation_fn=tf.nn.sigmoid):\n",
        "  \"\"\"Generate images from latents.\"\"\"\n",
        "  with slim.arg_scope([slim.fully_connected, slim.conv2d_transpose],\n",
        "                      normalizer_fn=slim.batch_norm):\n",
        "    with slim.arg_scope([slim.conv2d_transpose], kernel_size=4, stride=2):\n",
        "      net = slim.fully_connected(z, 1024)\n",
        "      net = slim.fully_connected(net, 7 * 7 * 128)\n",
        "      net = tf.reshape(net, [-1, 7, 7, 128])\n",
        "      net = slim.conv2d_transpose(net, 64)\n",
        "      net = slim.conv2d_transpose(net, 1,\n",
        "                                  normalizer_fn=None,\n",
        "                                  activation_fn=None)\n",
        "      net = out_activation_fn(net)\n",
        "      return net\n",
        "    \n",
        "def discriminator(x, cat_dim, cont_dim, fix_cont_std=True):\n",
        "  \"\"\"Discriminate real vs. fake and predict latents from an input image.\n",
        "  \n",
        "  Args:\n",
        "    x: Tensor of images\n",
        "    cat_dim: dimension of categorical variable\n",
        "    cont_dim: number of continuous latent variables\n",
        "    fix_cont_std: whether to fix the standard deviation of the approximate\n",
        "      posterior for the continuous latent variables to 1.0 \n",
        "      \n",
        "  Returns:\n",
        "    q_real: predicted distribution over real vs. fake\n",
        "    q_cat: predicted distribution over categorical variable\n",
        "    q_cont: predicted distribution over continuous variable\n",
        "  \"\"\"\n",
        "  with slim.arg_scope([slim.conv2d, slim.fully_connected],\n",
        "                      activation_fn=tf.nn.leaky_relu):\n",
        "    with slim.arg_scope([slim.conv2d], kernel_size=4, stride=2):\n",
        "      net = slim.conv2d(x, 64, normalizer_fn=None)\n",
        "      net = slim.conv2d(net, 128, normalizer_fn=slim.batch_norm)\n",
        "      net = slim.flatten(net)\n",
        "      net = slim.fully_connected(net, 1024, normalizer_fn=slim.batch_norm)\n",
        "\n",
        "      # Logits for binary real vs. fake GAN discriminator\n",
        "      logits_real = slim.fully_connected(net, 1, activation_fn=None)\n",
        "      q_real = tfd.Bernoulli(logits=logits_real)\n",
        "\n",
        "      # Recognition network for latent variables has an additional layer \n",
        "      encoder = slim.fully_connected(net, 128, normalizer_fn=slim.batch_norm)\n",
        "\n",
        "      # Compute logits for each category of categorical latent\n",
        "      logits_cat = slim.fully_connected(encoder, cat_dim, activation_fn=None)\n",
        "      q_cat = tfd.Categorical(logits=logits_cat)\n",
        "\n",
        "      # Compute mean and variance for Gaussian posterior of continuous latents\n",
        "      cont_vars = slim.fully_connected(encoder, cont_dim * 2, activation_fn=None)\n",
        "      cont_mu = cont_vars[:, :cont_dim]\n",
        "      if fix_cont_std:\n",
        "        cont_sigma = tf.ones_like(cont_mu)\n",
        "      else:\n",
        "        cont_sigma = tf.nn.softplus(cont_vars[:, cont_dim:])\n",
        "      q_cont = tfd.Normal(loc=cont_mu, scale=cont_sigma)\n",
        "      return q_real, q_cat, q_cont"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "c78T8kQbrasy"
      },
      "source": [
        "## 파라메타 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6yGHehUroYJm",
        "colab": {}
      },
      "source": [
        "# infogan 파라메타 \n",
        "#  Incompressible noise dimensionality (not reconstructed)\n",
        "noise_dim = 62\n",
        "#  Dimensionality of the single categorical variable\n",
        "cat_dim = 10\n",
        "#  Number of continuous latent variables\n",
        "cont_dim = 2\n",
        "#  Weighting on InfoGAN regularization term\n",
        "info_reg_coeff = 1.0\n",
        "\n",
        "# 하이퍼파라메타\n",
        "#  Generator/discriminator learning rate\n",
        "gen_lr = 1e-3 # 생성기 Learning rate\n",
        "disc_lr = 2e-4 # 판별기 Learning rate\n",
        "NB=128 # batch size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XYe4yPaEodkh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "outputId": "9c80be39-0e3b-4eb9-e4e0-4aec1c386017"
      },
      "source": [
        "#데이터셋 \n",
        "tf.reset_default_graph()\n",
        "images_np = mnist.train.images\n",
        "images_np = images_np.reshape(-1, 28, 28, 1)\n",
        "dataset = tf.data.Dataset.from_tensor_slices(images_np)\n",
        "dataset = dataset.shuffle(100).repeat()\n",
        "dataset = dataset.apply(\n",
        "    tf.contrib.data.batch_and_drop_remainder(NB))\n",
        "images = dataset.make_one_shot_iterator().get_next()\n",
        "\n",
        "# Generate samples from prior\n",
        "z_cat = tfd.Categorical(logits=tf.zeros([NB, cat_dim])).sample()\n",
        "z_cat_one_hot = tf.one_hot(z_cat, cat_dim)\n",
        "\n",
        "z_noise = tfd.Uniform(low=-tf.ones([NB, noise_dim]),\n",
        "                      high=tf.ones([NB, noise_dim])).sample()\n",
        "z_cont = tfd.Uniform(low=-tf.ones([NB, cont_dim]),\n",
        "                     high=tf.ones([NB, cont_dim])).sample()\n",
        "# Concatenate incompressible noise, discrete latents, and continuous latents\n",
        "z = tf.concat([z_noise, z_cat_one_hot, z_cont], axis=1)\n",
        "\n",
        "# Construct generator and discriminator networks\n",
        "with slim.arg_scope(\n",
        "    [slim.fully_connected, slim.conv2d_transpose],\n",
        "    weights_initializer=tf.random_normal_initializer(stddev=0.02)):\n",
        "  with slim.arg_scope(\n",
        "      [slim.conv2d],\n",
        "      weights_initializer=tf.truncated_normal_initializer(stddev=0.02)):\n",
        "    with tf.variable_scope('gnet'):\n",
        "      with slim.arg_scope([slim.batch_norm], is_training=True):\n",
        "        generated = generator(z)\n",
        "    with tf.variable_scope('gnet', reuse=True):\n",
        "      with slim.arg_scope([slim.batch_norm], is_training=False):\n",
        "        generated_test = generator(z)\n",
        "    with tf.variable_scope('dnet'):\n",
        "      d_real, cat_real, cont_real = discriminator(images, cat_dim, cont_dim)\n",
        "    with tf.variable_scope('dnet', reuse=True):\n",
        "      d_fake, cat_fake, cont_fake = discriminator(generated, cat_dim, cont_dim)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0825 16:19:25.754715 140166383638400 deprecation.py:323] From <ipython-input-5-df9439984869>:7: batch_and_drop_remainder (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.batch(..., drop_remainder=True)`.\n",
            "W0825 16:19:25.761837 140166383638400 deprecation.py:323] From <ipython-input-5-df9439984869>:8: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n",
            "W0825 16:19:27.182322 140166383638400 deprecation.py:323] From <ipython-input-5-df9439984869>:11: Categorical.__init__ (from tensorflow.python.ops.distributions.categorical) is deprecated and will be removed after 2019-01-01.\n",
            "Instructions for updating:\n",
            "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
            "W0825 16:19:27.188260 140166383638400 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/distributions/categorical.py:242: Distribution.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.\n",
            "Instructions for updating:\n",
            "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
            "W0825 16:19:27.191061 140166383638400 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/distributions/categorical.py:278: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.random.categorical` instead.\n",
            "W0825 16:19:27.217840 140166383638400 deprecation.py:323] From <ipython-input-5-df9439984869>:15: Uniform.__init__ (from tensorflow.python.ops.distributions.uniform) is deprecated and will be removed after 2019-01-01.\n",
            "Instructions for updating:\n",
            "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
            "W0825 16:19:28.687653 140166383638400 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "W0825 16:19:28.955217 140166383638400 deprecation.py:323] From <ipython-input-3-debb3f901fb3>:41: Bernoulli.__init__ (from tensorflow.python.ops.distributions.bernoulli) is deprecated and will be removed after 2019-01-01.\n",
            "Instructions for updating:\n",
            "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
            "W0825 16:19:29.033446 140166383638400 deprecation.py:323] From <ipython-input-3-debb3f901fb3>:57: Normal.__init__ (from tensorflow.python.ops.distributions.normal) is deprecated and will be removed after 2019-01-01.\n",
            "Instructions for updating:\n",
            "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qCa2lSXCohCX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "a4f078a3-f4e9-42cd-f82a-8caa3210fd28"
      },
      "source": [
        "# Normal GAN objectives\n",
        "real_labels = tf.ones([NB, 1])\n",
        "fake_labels = tf.zeros([NB, 1]) \n",
        "gan_d_loss = -(tf.reduce_mean(d_real.log_prob(real_labels)) + \n",
        "               tf.reduce_mean(d_fake.log_prob(fake_labels)))\n",
        "gan_g_loss = -tf.reduce_mean(d_fake.log_prob(real_labels))\n",
        "\n",
        "# InfoGAN loss\n",
        "log_prob_cat = tf.reduce_sum(cat_fake.log_prob(z_cat)) / NB\n",
        "log_prob_cont = tf.reduce_sum(cont_fake.log_prob(z_cont)) / NB\n",
        "infogan_loss = -info_reg_coeff * (log_prob_cat + log_prob_cont)\n",
        "\n",
        "# Generator and discriminator loss are the same as a GAN but with the added\n",
        "# regularization to reconstruct a subset of latents from the image\n",
        "d_loss = gan_d_loss + infogan_loss\n",
        "g_loss = gan_g_loss + infogan_loss\n",
        "\n",
        "# Optimization\n",
        "global_step = tf.train.get_or_create_global_step()\n",
        "dvars = tf.contrib.framework.get_variables('dnet')\n",
        "gvars = tf.contrib.framework.get_variables('gnet')\n",
        "gen_opt = tf.train.AdamOptimizer(gen_lr, 0.5)\n",
        "disc_opt = tf.train.AdamOptimizer(disc_lr, 0.5)\n",
        "train_gen_op = gen_opt.minimize(g_loss, global_step, var_list=gvars)\n",
        "update_ops = (tf.get_collection(tf.GraphKeys.UPDATE_OPS))\n",
        "with tf.control_dependencies(update_ops + [train_gen_op]):\n",
        "  train_op = disc_opt.minimize(d_loss, global_step, var_list=dvars)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0825 16:19:29.152923 140166383638400 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ktPNPZJ_ojB-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "308b1ad5-9c04-422e-df24-598f844c8397"
      },
      "source": [
        "'''\n",
        "from IPython.display import display\n",
        "import matplotlib.pyplot as plt\n",
        "plt.ioff()\n",
        "def display_imgs(gens):\n",
        "  fig, axs = plt.subplots(1, 10, figsize=(10, 1))\n",
        "  for i in range(10):\n",
        "    axs.flat[i].imshow(gens[i].squeeze(), interpolation='none', cmap='gray')\n",
        "    axs.flat[i].axis('off');\n",
        "  return fig, axs\n",
        "'''"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nfrom IPython.display import display\\nimport matplotlib.pyplot as plt\\nplt.ioff()\\ndef display_imgs(gens):\\n  fig, axs = plt.subplots(1, 10, figsize=(10, 1))\\n  for i in range(10):\\n    axs.flat[i].imshow(gens[i].squeeze(), interpolation='none', cmap='gray')\\n    axs.flat[i].axis('off');\\n  return fig, axs\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jl_kuC9sriVr"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "u14BRCiKolCP",
        "outputId": "2ddbab4c-8934-4191-ae7f-b4399dd95292",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "sess = tf.InteractiveSession()\n",
        "sess.run(tf.initialize_all_variables())\n",
        "steps = 1000\n",
        "\n",
        "outs = []\n",
        "for i in range(steps+1):\n",
        "  out = sess.run([train_op, global_step, log_prob_cat, log_prob_cont, infogan_loss, gan_d_loss, gan_g_loss, generated])\n",
        "  outs.append(out[1:-1])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py:1735: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
            "  warnings.warn('An interactive session is already active. This can '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tBWBqXIWrqpX"
      },
      "source": [
        "## Visualization\n",
        "### Infogan의 특징을 확인해보면 Discrete는 각 MNIST의 label의 feature를 보여주며 Continuoust는 rotation, thickness등의 feature를 보여준다.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wptae0erozJ_",
        "colab": {}
      },
      "source": [
        "np_z = sess.run(z)\n",
        "# C를 interpolation해서 보여준다.\n",
        "for interp in ('continuous-1', 'continuous-2', 'discrete'):\n",
        "  for i in range(4):\n",
        "    z_new = np_z.copy()\n",
        "    z_new[:] = z_new[i:i+1]\n",
        "    if 'continuous' in interp:\n",
        "      idx = int(interp.split('-')[1])\n",
        "      z_new[:10, -idx] = np.linspace(-2, 2, 10)\n",
        "    else:\n",
        "      z_new[:cat_dim, noise_dim:noise_dim+cat_dim] = np.eye(cat_dim)\n",
        "    samples = sess.run(generated_test, {z: z_new})\n",
        "    display_imgs(samples);\n",
        "    plt.suptitle(interp + ' interpolation')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epCuOrqe01Ki",
        "colab_type": "text"
      },
      "source": [
        "## Reference \n",
        "---\n",
        "### 구현 저자 : Ben Poole, Kumar Krishna Agrawal  \n",
        "\n",
        "[https://colab.research.google.com/drive/1JkCI_n2U2i6DFU8NKk3P6EkPo3ZTKAaq#scrollTo=qCa2lSXCohCX](https://colab.research.google.com/drive/1JkCI_n2U2i6DFU8NKk3P6EkPo3ZTKAaq#scrollTo=qCa2lSXCohCX)  \n",
        "### 참고하기 좋은 코드:\n",
        "[https://github.com/jiema58/InfoGan-Mnist/blob/master/InfoGan.ipynb](https://github.com/jiema58/InfoGan-Mnist/blob/master/InfoGan.ipynb)  \n",
        "[https://github.com/openai/InfoGAN](https://github.com/openai/InfoGAN)  \n",
        "### Infogan 이론 자료 :  \n",
        "[1]InfoGAN 논문 [https://arxiv.org/abs/1606.03657](https://arxiv.org/abs/1606.03657)  \n",
        "[2]infoGAN 이론 설명(영문) [https://towardsdatascience.com/infogan-generative-adversarial-networks-part-iii-380c0c6712cd](https://towardsdatascience.com/infogan-generative-adversarial-networks-part-iii-380c0c6712cd)   \n",
        "[3]infoGAN 이론 설명(한글) [https://taeoh-kim.github.io/blog/generative-models-part-2-improvedganinfoganebgan](https://taeoh-kim.github.io/blog/generative-models-part-2-improvedganinfoganebgan)  \n",
        "### 이미지자료 참고 :\n",
        "[1] https://github.com/NRauschmayr/InfoGAN_Gluon/blob/master/InfoGAN.ipynb\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8F8TGHKBo4oA",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}